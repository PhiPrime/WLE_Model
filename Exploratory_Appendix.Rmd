---
title: "Exploratory_Appendix"
author: "Luke Coughlin"
output: 
        html_document:
        keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# What is this Document?  
Often when first obtaining data one will inspect it to understand how it works. I feel documenting what is done is helpful for reproducibility and transparency. However the amount of output that one views isn't always nessacry to be included in the full report, as such I'll keep all this exploratory code and display it here, along with some thoughts when appropriate.  

# Load Data  
```{r}
trurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trdest <- paste0(getwd(), "/Data/training.csv")
download.file(trurl, trdest)
training <- read.csv(trdest)
```

# Explore  
```{r}
str(training)
```


## Investigating `num_window`  
```{r}
library(tidyverse)
grouped <- group_by(training, num_window)
uni <- summarise(grouped, unique(user_name))
nrow(uni); max(grouped$num_window)
gaps <- sapply(2:nrow(uni), function(x){
        uni$num_window[x] != uni$num_window[x - 1] + 1})
gaps <- sapply(1:length(gaps), function(x){
        any(c(gaps[x - 1], gaps[x], gaps[x + 1]))})
gaps <- c(gaps, TRUE)
uni[gaps,] #Ends on 864, just like max, others are just missing nos
```

## Investigating `NA` Values  
```{r}
colS <- colSums(is.na(grouped) | grouped[,1:ncol(grouped)] == "")
names(colS[colS != 0])
##19216 is consistantly reported and on summary variables
all(colS[colS != 0] == 19216)
## I reckon they are only NA when `new_window` is "no"
newWindows <- which(training$new_window == "yes")
any(colSums(is.na(grouped[grouped$new_window == "yes",])) != 0)
```
This is good, it means there isn't any truely missing data, perhaps the gaps in `num_window` were from botched test that were appropriately discarded. I am not concerned with any missing values now. For exploring we're going to subset out these summary variables  
```{r}
summaries <- names(colS[colS != 0])
expdat <- select(training, -summaries)
names(expdat)
```




## Investigating Time Variables  

```{r}
library(lubridate)
set.seed(1618)
#do{
bar <- sample(1:nrow(expdat), 1)
foo <- expdat[(bar - 2):(bar + 2),]
#} 
while (any(foo$num_window != unique(foo$num_window))) {#runs once with seed
bar <- sample(1:nrow(expdat), 1)
foo <- expdat[(bar - 2):(bar + 2),]
}

foo <- data.frame(p1 = foo$raw_timestamp_part_1,
                  p2 = foo$raw_timestamp_part_2,
                  dmYHM = foo$cvtd_timestamp)
foo
```
```{r}
uniT <- as.numeric(as.POSIXct(
        as.character(foo$dmYHM), format = "%d/%m/%Y %H:%M"))
data.frame(uniT, uniT - foo$p1, foo$p2)
```
**I shall return to this later**  

## Tidying Data  
At least for exploratory purposes these data are identified by their `num_window`, then we have a device: belt, arm, dumbbell, or forearm. With each device measuring rotation, acceleration, angle, or magnet in one of three dimensions. There is also a `classe` for determining the method.

As such I'm going to melt the exploratory data such that there is a `num_window`, `device`, `measurement`, `dimension`, `value`, and `classe`. This should help further my understanding of the data to help with creating a model.  
```{r}

```
 


## Graphs  


# Benchmarks

```{r}
classeCounts <- colSums(table(grouped$num_window, grouped$classe))
classeCounts
classeCounts/nrow(grouped)
```
These would be the probabilities if one were to just randomly guess. However it should be noted that the true population these predictions would be applied to likely would not follow the same distribution (For example, an individual could make mistake C quite frequently such that the occurance is greater than this proportion of our training data)  




